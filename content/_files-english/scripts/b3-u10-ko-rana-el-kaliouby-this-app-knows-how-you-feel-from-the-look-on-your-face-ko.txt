00:12	우리의 감정들은  삶의 모든 면에 영향을 줍니다, 우리의 건강과 학습부터 사업의 방식과 의사결정까지요. 큰 일이든 작은 일이든지요. 또한 감정은 우리가 서로를 어떻게  연결시키는지 영향을 주죠. 우리는 이런 세상에서  살기위해 진화해왔죠. 그러나 대신에 우리는 점점 더 이런 삶 속에 살고 있습니다. 어젯밤 제 딸의 문자 메세지입니다. 감정이 결여된 세상이죠. 저는 그것을 바꾸는 과제에 착수했어요. 감정을 디지털 공간의  경험안에 도입시키고 싶었죠.
00:48	전 이걸 15년 전에 시작했어요. 저는 이집트에서 컴퓨터 공학자였고 막 캠브리지의 박사 학위  과정에 입학했었습니다. 그래서 저는 좀 다른 것을 했습니다. 어린 신혼의 무슬림  이집트 부인으로서요. 이집트에 남아야했던 남편의 지원 덕분에 저는 짐을 꾸려 영국으로 갔습니다. 고향에서 수천 마일 떨어진 캠브리지에서 사람들과 지내는 시간보다 많은 시간을  노트북과 보내고 있음을 알았습니다. 이런 친밀성에도 불구하고 제 노트북은 저의 감정을 알 수 없었죠. 이것은 제가 행복한지, 기분이 안 좋은지, 스트레스를 받는지, 혼란스러운지  알지 못했습니다. 그게 답답했어요. 더 안 좋은 상황은 온라인상으로  고향 가족들과 대화할 때 제 모든 감정들이 사이버 공간에서  사라진다고 느껴졌어요. 저는 향수병을 앓았고, 외로웠으며, 그리고 어떤날은 정말로 울었죠. 그러나 제가 표현할 수 있는 방법은 이것뿐이었습니다. (웃음) 오늘날의 기술은 높은 I.Q를  가지고 있습니다. 그러나 E.Q는 없어요. 인지 지능이 있으나 감성 지능은 없죠. 그래서 생각하게 됐습니다. 기술이 우리의 감정을 느낀다면 어떨까? 장비들이 우리의 감정을 느끼고  그에 따라 반응한다면 어떨까? 감수성이 있는 친구가  반응하듯이 말이죠. 이런 의문들 때문에 저와 동료들이 감정을 읽고 반응하는  기술을 만들었습니다. 우리의 시작점은 인간의 얼굴이었죠.
02:30	인간의 얼굴은 하나의 강력한 경로인데 사회적, 감정적 상태의  소통을 위해 모두가 사용하죠. 즐거움, 놀람, 공감과  호기심같은 감정들입니다. 감정 과학에서 각 얼굴 근육의 움직임을  활동 단위라고 합니다. 예를들어, 활동 단위 12번은 이건 헐리우드 대작이 아니예요. 입술의 가장자리를 당기는 것입니다. 웃음의 주요 구성 부분이죠. 모두 시도해보세요. 웃어 보세요. 다른 예로 활동 단위 4번은  눈썹을 찡그리는 것입니다. 당신이 두 눈썹을 함께 모을 때 이런 느낌과 주름살이 생깁니다. 우리가 별로 좋아하지 않죠. 그건 부정적 감정의 강한 지표입니다. 약 45개의 활동 단위가 있어요. 조합해서 수백개의 감정표현이 생깁니다.
03:18	이런 표정을 읽도록 컴퓨터를  가르치는 것은 힘듭니다. 활동 단위들은 빠를 수도 있고,  미묘할 수 도 있으며 수 많은 방법으로 조합되기 때문입니다. 예로 웃음과 억지웃음을 들어봅시다. 그것들은 다소 비슷해 보이죠. 그러나 매우 의미가 다릅니다. (웃음) 웃음은 긍정적이고, 억지웃음은 보통은 부정적입니다. 가끔 억지웃음으로  유명해질 수 있어요. 농담이 아니라 컴퓨터가 두 표정의 차이를  구별하는 것은 중요합니다.
03:50	그래서 저희는 어떻게 했을까요? 저희는 컴퓨터 알고리즘에 십만개의 웃는 사람들  예시를 입력했습니다. 인종, 나이, 성별이 다양합니다. 억지웃음도 그렇게 했습니다. 딥 러닝 인공지능을 사용해서 알고리즘이 느낌과 주름살,  얼굴의 형태 변화를 찾습니다. 모든 웃는 얼굴에 공통적 특징이  있다는 것을 학습하게 됩니다. 모든 억지웃음은 미묘하게  다른 특징을 가지고 있어요. 그리고나서 이것은  새로운 얼굴을 관찰합니다. 이 얼굴이 웃음과 같은  특징을 가진다는 것을 알고 말합니다."아하, 알겠습니다.  이건 웃는 표정입니다."
04:30	이 기술이 어떻게 작동하는지 보여주는 가장 좋은 방법은 실제 시연을 시도하는 것이죠. 저는 지원자 한 분이 필요해요. 얼굴을 가진 분을 선호합니다. (웃음) 클로이가 오늘 지원해줄 겁니다. 지난 5년 동안, 우리는 MIT에서 연구로 시작해  한 회사를 설립했습니다. 저희 팀이 이 기술을  실현하려고 노력하는 곳이죠. 저희는 야생의 상태라고 불러요. 그리고 우리는 기술을 소형화해서 핵심 감정 엔진이 아이패드처럼 카메라달린  이동식 장치에도 쓸 수 있게 했습니다. 자, 시도해봅시다.
05:06	여러분이 보듯이, 이것은 클로이의 얼굴을  감지하고 있습니다. 여기 하얀 테두리가 있죠. 이것은 그녀의 얼굴의  눈썹, 눈, 입과 코와 같은 주요 특정 부분을 추적하고 있습니다. 궁금한것은 이게 그녀의 표정을  인식할 수 있을까요? 그래서 이 기계를 시험해볼거예요. 먼저 무표정을 해주세요.  좋아요, 멋지네요. (웃음) 순수한 웃음이죠, 멋져요. 웃을 때 녹색 막대가  증가하는 것을 볼 수 있죠. 함박웃음이었어요. 미묘한 웃음을 해보시겠어요? 컴퓨터가 인식하는지 보려고요. 미묘한 웃음도 인식합니다. 이것을 만들려고 정말 노력했어요. 눈썹이 올라가면 놀람의 표시이죠. 이마의 주름살은 혼란의 표시입니다. 찡그려주세요. 네, 완벽하네요. 이것은 각각 다른 활동단위이고 더 많이 있습니다. 이건 몇가지만 보여드린 겁니다. 저희는 각각의 인식을  감정 정보점이라고 합니다. 이것이 함께 여러가지  감정을 나타나게 합니다. 오른쪽에는 당신이 행복해 보입니다. 이것은 기쁨입니다. 기쁨 기능이 작동하죠. 혐오하는 표정을 지어주세요. 자인이 One Direction을  탈퇴했다고 생각해보세요. (웃음) 네, 코에 주름을 잡아보세요. 좋아요. 유의성이 부정적이네요, 그러니까 진짜 팬이었나보네요. 유의성은 한 경험이 얼마나 긍정적 또는 부정적인지 나타냅니다. 참여도는 얼마나 표현력이  있느냐를 보여줍니다. 클로이가 실시간 감정 변화에  접근할 수 있다고 상상해 보세요. 그녀는 이것을 원하는 사람과  공유할 수 있겠죠. 감사합니다. (박수)
06:45	지금까지 120억개의  감정 정보점을 수집했습니다. 세상에서 가장 큰 감정 데이터베이스죠. 2,900만개의  얼굴 영상에서 모았습니다. 감정 공유에 동의한 분들이고 세계의 75개국에서 모았습니다. 이것은 매일 늘어나고 있습니다. 저는 이것이 놀랍습니다. 지금 우리는 감정과 같은 개인적인 것을 수량화 할 수 있는거죠. 그리고 이런 규모로 할 수 있습니다.
07:11	최근까지 연구한 것은 무엇일까요? 성별입니다. 저희 정보가 여러분이  설마하는 것을 확인시켜 줄 겁니다. 여자가 남자보다 표현력이 있습니다. 더 많이 웃고 더 오래 웃어요. 우리는 수량화할 수 있어요. 여성과 남성이 다르게 반응하는 것을요. 문화적으로는 미국에서 여성들이  남성보다 40% 더 표현력이 좋아요. 그런데 신기하게도  영국에서는 차이가 없네요. (웃음) 나이는요. 50대 혹은 그 이상의 사람들이 젊은 사람들보다 25% 더 감정적입니다. 20대 여성들은 또래 남성보다  25% 더 많이 웃습니다. 아마 데이트를 위해 필요한 것이겠죠. 하지만 이 자료에서 놀라운 점은 우리가 언제나 표현력이  있다는 것입니다. 혼자 기계 앞에 앉아 있을때도요. 페이스북의 고양이 영상을  볼 때 뿐만 아니라 메일을 보낼 때, 문자를 할 때,  그리고 온라인 쇼핑을 하거나 심지어 세금을 지불할 때도 표현합니다.
08:17	오늘날 이 자료가 어디에 사용될까요? 우리가 매체와 소통하는 방법과 대박영상 특징이나  투표 성향을 이해하고
08:24	그리고 자율권을 주거나  감정 기능 기술을 이해하는 겁니다. 제 마음에 가장 와닿는  예를 보여드리고 싶습니다. 이 감정 기능 안경은  사람들을 돕습니다. 시각기능이 약화된 사람들이 다른 이들의 감정을 읽게 해줍니다. 또한 자폐증이 있는 사람이  감정을 해석하게 해줍니다. 정말로 힘들어 하는 것이지요. 교육에서 학습프로그램이 당신이  혼란스럽고 지쳐간다는 것을 감지하거나 또는 지루하거나, 흥분하는 것을  감지하는 걸 상상해 보세요. 교실에서 정말 좋은 선생님이  그러는 것처럼요. 손목시계가 감정을 감지한다면 어떨까요. 자동차가 여러분이  피곤하다는 것을 안다면요. 아니면 냉장고가 당신이  스트레스를 받았다는 것을 알아서 냉장고가 자동으로 잠궈서  폭식을 막아 준다면요. (웃음) 전 좋을거 같아요. 제가 캠프리지에 있었을때, 이 실시간 감정 흐름에  접근할 수 있었다면 어땠을까요. 고향에 가족과 공유할 수 있었을겁니다. 매우 자연스럽게  모두 같은 방에 있는 것처럼요.
09:27	제 생각에 5년 후에는 모든 기계들이 감정칩을 가질겁니다. 이렇게 반응하는 기기가  어땠는지 기억도 못할 겁니다. 기기앞에서 그저 찌푸리지만 않고 "별로 안좋으신가봐요, 그렇죠?" 하는 겁니다. 가장 큰 과제는 이 기술에  많은 응용이 있다는 것입니다. 저희 팀원들은 우리가 모든 것을  만들 수 없다는 걸 깨달았습니다. 그래서 다른 개발자들이 함께 이 기술을 사용할 수 있게 했습니다. 저희는 잠재적인 위험성과  악용의 가능성이 있음을 압니다. 그러나 개인적으로 이 일에  수년을 보낸 사람으로서 감정 지능 기술이 인류에게 줄 혜택이 악용의 가능성보다  훨씬 크다고 믿습니다. 여러분이 이 대화의 부분으로  참여하도록 초대했어요. 더 많은 사람들이 이 기술을 알수록 어떻게 사용되는지  더 많은 의견을 들을 수 있어요. 점점 더 우리의 삶이 디지털화 되면서 우리 감정을 되찾고자 기기사용을 억제하는  승산없는 싸움을 하고 있습니다. 대신에 제가 시도하는 것은 감정들을 기술로 가져오는 것이에요. 기술이 보다 반응할 수 있도록 만들죠. 우리를 갈라놓은 기계들이 우리를 재화합할 수 있게 하고 싶어요. 기술을 인간적이게 만들어서 우리는 최고의 기회를 얻었죠. 어떻게 우리가 기계들과  소통하는지 재고하는 겁니다. 따라서 우리 인간이 다른 이들과  소통하는 방법도 재고하는 겁니다.
10:57	감사합니다. (박수)
